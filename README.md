
# Multimodal Emotion Recognition

Welcome to the Multimodal Emotion Recognition project! This project focuses on recognizing emotions from both text and audio using Wav2Vec2 and BERT models.

## Introduction

Emotion recognition involves identifying the emotional state of a person based on their speech and text. In this project, we leverage the power of Wav2Vec2 for audio and BERT for text to perform emotion recognition using a multimodal dataset.

## Dataset

For this project, we will use a custom dataset of text and audio samples. You can create your own dataset and place it in the `data/emotion_data.csv` file.

## Project Overview

### Prerequisites

- Python 3.6 or higher
- PyTorch
- Hugging Face Transformers
- Librosa
- Pandas

### Installation

To set up the project, follow these steps:

```bash
# Clone this repository and navigate to the project directory:
git clone https://github.com/your-username/...
# Install the required packages:
pip install -r requirements.txt

```
